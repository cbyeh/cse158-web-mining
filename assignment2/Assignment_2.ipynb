{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict # Dictionaries with default values\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse each json object\n",
    "def read_JSON(path):\n",
    "    for l in gzip.open(path, 'r'):\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://cseweb.ucsd.edu/~jmcauley/datasets.html#clothing_fit (Rent The Runway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = []\n",
    "for d in read_JSON('renttherunway_final_data.json.gz'):\n",
    "    data.append(d)\n",
    "\n",
    "# Filter data without a rating\n",
    "for d in data:\n",
    "    if not d['rating']:\n",
    "        data.remove(d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic Statistics and Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original data set = 192462 samples\n",
      "Number of features = 15 features\n"
     ]
    }
   ],
   "source": [
    "# Size of dataset\n",
    "print(\"Size of original data set =\", len(data), \"samples\")\n",
    "\n",
    "# Number of features\n",
    "print(\"Number of features =\", len(data[0]), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit': 'fit',\n",
       " 'user_id': '420272',\n",
       " 'bust size': '34d',\n",
       " 'item_id': '2260466',\n",
       " 'weight': '137lbs',\n",
       " 'rating': '10',\n",
       " 'rented for': 'vacation',\n",
       " 'review_text': \"An adorable romper! Belt and zipper were a little hard to navigate in a full day of wear/bathroom use, but that's to be expected. Wish it had pockets, but other than that-- absolutely perfect! I got a million compliments.\",\n",
       " 'body type': 'hourglass',\n",
       " 'review_summary': 'So many compliments!',\n",
       " 'category': 'romper',\n",
       " 'height': '5\\' 8\"',\n",
       " 'size': 14,\n",
       " 'age': '28',\n",
       " 'review_date': 'April 20, 2016'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example sample\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42462"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training and test data\n",
    "random.shuffle(data)\n",
    "training_data = data[:150000]\n",
    "test_data = data[150000:]\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Features: fit, user_id, bust_size, item_id, rented_for, category, body_type, review_date\n",
    "\n",
    "* Numerical Features: weight, size, height, age\n",
    "\n",
    "* Ordinal Features: rating, review_text, review_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictive task is predicting a user's rating on a review of their clothing fit on some given features. \n",
    "\n",
    "One naive baseline predictive model we can use is simply determining if the customer considered the clothing item as \"fit\", which means the item was neither \"small\" nor \"large\". This is a good sign the the customer was satisfied, so we simply guess the rating to be \"10\". Otherwise we guess a random lesser rating from all other possible ratings in the training data. To get these other ratings, we iterated through the training data, and put them in a set.\n",
    "\n",
    "Another naive baseline we can do is selectively find the most common words that are not stop-words used in each rating category. For example, in a \"10\" words that appear may be \"perfect\" or \"great\". We can manually select qualitative words for each category, and our predictor would simply predict that rating if those words appear in a review. We found these words by finding the top 30 most frequent non-stop-words for each rating category in the training data. For reviews that have overlapping words in multiple rating categories, the higher rating category would take precedence.\n",
    "\n",
    "For our focal predictors, we decided to train logistic regressors with other features // TODO:\n",
    "\n",
    "We can validify our predictions by // TODO: Our baselines were in the 50-60% accuracy range, which is decent considering there are 5 possible predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of other ratings: {'6', '4', '8', '2'}\n",
      "Baseline Accuracy = 0.5576750977344449\n"
     ]
    }
   ],
   "source": [
    "# Baseline 1: Predict a rating of 10 if the fit = 'fit', otherwise randomly predict a rating in the range\n",
    "# of all other rating in the data set\n",
    "\n",
    "# Find ratings that aren't 10\n",
    "other_ratings = set()\n",
    "for d in data:\n",
    "    if d['rating'] != '10':\n",
    "        other_ratings.add(d['rating'])\n",
    "print(\"Set of other ratings:\", other_ratings)\n",
    "\n",
    "\n",
    "def baseline1(data, y):\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        if d['fit'] == 'fit':\n",
    "            predictions.append('10')\n",
    "        else:\n",
    "            predictions.append(random.choice(list(other_ratings)))\n",
    "    return predictions\n",
    "\n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = baseline1(test_data, y_test)\n",
    "correct = [y_test[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Baseline Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words per category\n",
      "2 : ['dress', 'wear', 'fit', 'size', 'would', 'like', 'didnt', 'even', 'small', 'way', 'look', 'short', 'really', 'big', 'im', 'looked', 'wearing', 'tight', 'long', 'made', 'back', 'large', 'could', 'top', 'material', 'fabric', 'also', 'chest', 'couldnt', 'ordered'] \n",
      "\n",
      "4 : ['dress', 'fit', 'wear', 'size', 'would', 'didnt', 'like', 'really', 'small', 'look', 'top', 'wearing', 'short', 'also', 'tight', 'way', 'fabric', 'im', 'back', 'long', 'even', 'big', 'looked', 'waist', 'large', 'made', 'material', 'could', 'pretty', 'great'] \n",
      "\n",
      "6 : ['dress', 'fit', 'would', 'size', 'wear', 'didnt', 'little', 'like', 'really', 'top', 'great', 'bit', 'look', 'small', 'short', 'tight', 'also', 'im', 'fabric', 'long', 'wearing', 'waist', 'color', 'pretty', 'back', 'wore', 'beautiful', 'work', 'made', 'big'] \n",
      "\n",
      "8 : ['dress', 'fit', 'size', 'would', 'little', 'wear', 'great', 'wore', 'bit', 'comfortable', 'loved', 'compliments', 'perfect', 'really', 'like', 'im', 'didnt', 'long', 'top', 'tight', 'got', 'back', 'definitely', 'color', 'bra', '4', 'length', 'night', 'short', 'fabric'] \n",
      "\n",
      "10 : ['dress', 'fit', 'size', 'would', 'wore', 'perfect', 'wear', 'great', 'comfortable', 'little', 'compliments', 'loved', 'like', 'got', 'bra', 'definitely', 'night', 'length', 'im', 'long', 'bit', 'rent', 'didnt', 'back', 'heels', 'really', 'color', 'flattering', 'wedding', '4'] \n",
      "\n",
      "Most common rating: 10\n"
     ]
    }
   ],
   "source": [
    "# Baseline 2 preparation: Find most common words that aren't stop words\n",
    "\n",
    "# Find most common words that aren't stop words\n",
    "punct = string.punctuation\n",
    "\n",
    "r2_word_count = defaultdict(int)\n",
    "r4_word_count = defaultdict(int)\n",
    "r6_word_count = defaultdict(int)\n",
    "r8_word_count = defaultdict(int)\n",
    "r10_word_count = defaultdict(int)\n",
    "\n",
    "rating_count = defaultdict(int)\n",
    "for d in data:\n",
    "    t = d['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # Non-punct characters\n",
    "    t = ''.join(t) # Convert back to string\n",
    "    words = t.strip().split() # Tokenizes\n",
    "    \n",
    "    rating_count[d['rating']] += 1\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            if d['rating'] == '2':\n",
    "                r2_word_count[w] += 1\n",
    "            elif d['rating'] == '4':\n",
    "                r4_word_count[w] += 1\n",
    "            elif d['rating'] == '6':\n",
    "                r6_word_count[w] += 1\n",
    "            elif d['rating'] == '8':\n",
    "                r8_word_count[w] += 1\n",
    "            elif d['rating'] == '10':\n",
    "                r10_word_count[w] += 1\n",
    "\n",
    "def top_words(word_count):\n",
    "    counts = [(word_count[w], w) for w in word_count]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    return [w[1] for w in counts[:30]]\n",
    "\n",
    "print(\"Most frequent words per category\")\n",
    "word_counts = [(2, r2_word_count), (4, r4_word_count), (6, r6_word_count), (8, r8_word_count), (10, r10_word_count)]\n",
    "for rating, count in word_counts:\n",
    "    print(rating, \":\", top_words(count), \"\\n\")\n",
    "\n",
    "rating_count = [(rating_count[w], w) for w in rating_count]\n",
    "rating_count.sort()\n",
    "rating_count.reverse()\n",
    "print(\"Most common rating: \" + rating_count[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Accuracy = 0.49698554001224626\n"
     ]
    }
   ],
   "source": [
    "# Baseline 2: Predict based on specific words that appear in the review\n",
    "\n",
    "def baseline2(data, y):\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        # If no review, just choose most common in training set\n",
    "        if not d['review_text']: # if \"review_text\" not in d\n",
    "            predictions.append('10')\n",
    "            continue\n",
    "        t = d['review_text']\n",
    "        t = t.lower() # lowercase string\n",
    "        t = [c for c in t if not (c in punct)] # Non-punct characters\n",
    "        t = ''.join(t) # Convert back to string\n",
    "        words = t.strip().split() # Tokenizes\n",
    "        if \"perfect\" in words:\n",
    "            predictions.append(str(rating_count[0][1]))\n",
    "        elif \"great\" in words:\n",
    "            predictions.append('8')\n",
    "        elif \"little\" in words:\n",
    "            predictions.append('6')\n",
    "        elif \"didnt\" in words:\n",
    "            predictions.append('4')\n",
    "        elif \"couldnt\" in words:\n",
    "            predictions.append('2')\n",
    "        else:\n",
    "            predictions.append(str(rating_count[0][1])) # Most common\n",
    "    return predictions\n",
    "            \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = baseline2(test_data, y_test)\n",
    "correct = [y_test[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Baseline Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Accuracy = 0.649286420799774\n"
     ]
    }
   ],
   "source": [
    "# Try logistic regressor that just takes into account the length of a review\n",
    "\n",
    "def length_feature(datum):\n",
    "    return [1, len(datum['review_text'])]\n",
    "\n",
    "X = [length_feature(d) for d in training_data]    \n",
    "y = [d['rating'] for d in training_data]\n",
    "model = linear_model.LogisticRegression(max_iter=150000)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_test = [length_feature(d) for d in test_data] \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = model.predict(X_test)\n",
    "correct = [y[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Logistic Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Justification for proposed model, optimizations, issues, model alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Literature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset citation:\n",
    "\n",
    "#### Decomposing fit semantics for product size recommendation in metric spaces\n",
    "\n",
    "Rishabh Misra, Mengting Wan, Julian McAuley\n",
    "\n",
    "*RecSys, 2018*\n",
    "\n",
    "http://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18e.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
