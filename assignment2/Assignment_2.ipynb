{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import math\n",
    "from urllib.request import urlopen\n",
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "\n",
    "import urllib\n",
    "import scipy.optimize\n",
    "import random\n",
    "from collections import defaultdict # Dictionaries with default values\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import string\n",
    "from nltk.stem.porter import *\n",
    "import ast\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse each json object\n",
    "def read_JSON(path):\n",
    "    for l in gzip.open(path, 'r'):\n",
    "        yield json.loads(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset: https://cseweb.ucsd.edu/~jmcauley/datasets.html#clothing_fit (Rent The Runway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = []\n",
    "for d in read_JSON('renttherunway_final_data.json.gz'):\n",
    "    data.append(d)\n",
    "\n",
    "# Filter data without a rating\n",
    "for d in data:\n",
    "    if not d['rating']:\n",
    "        data.remove(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Basic Statistics and Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of original data set = 192462 samples\n",
      "Number of features = 15 features\n"
     ]
    }
   ],
   "source": [
    "# Size of dataset\n",
    "print(\"Size of original data set =\", len(data), \"samples\")\n",
    "\n",
    "# Number of features\n",
    "print(\"Number of features =\", len(data[0]), \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit': 'fit',\n",
       " 'user_id': '420272',\n",
       " 'bust size': '34d',\n",
       " 'item_id': '2260466',\n",
       " 'weight': '137lbs',\n",
       " 'rating': '10',\n",
       " 'rented for': 'vacation',\n",
       " 'review_text': \"An adorable romper! Belt and zipper were a little hard to navigate in a full day of wear/bathroom use, but that's to be expected. Wish it had pockets, but other than that-- absolutely perfect! I got a million compliments.\",\n",
       " 'body type': 'hourglass',\n",
       " 'review_summary': 'So many compliments!',\n",
       " 'category': 'romper',\n",
       " 'height': '5\\' 8\"',\n",
       " 'size': 14,\n",
       " 'age': '28',\n",
       " 'review_date': 'April 20, 2016'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example sample\n",
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42462"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training and test data\n",
    "# random.shuffle(data)\n",
    "training_data = data[:150000]\n",
    "test_data = data[150000:]\n",
    "\n",
    "len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Categorical Features: fit, user_id, bust_size, item_id, rented_for, category, body_type, review_date\n",
    "\n",
    "* Numerical Features: weight, size, height, age\n",
    "\n",
    "* Ordinal Features: rating, review_text, review_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For categorical features determine options\n",
    "fit_options = set()\n",
    "rental_reasons = set()\n",
    "body_types = set()\n",
    "clothing_categories = set()\n",
    "\n",
    "for d in training_data:\n",
    "    fit_options.add(d['fit'])\n",
    "    if 'rented for' in d:\n",
    "        rental_reasons.add(d['rented for'])\n",
    "    if 'body type' in d:\n",
    "        body_types.add(d['body type'])\n",
    "    clothing_categories.add(d['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit Options:  large, fit, small \n",
      "\n",
      "Rental Reasons:  date, everyday, party: cocktail, wedding, vacation, other, work, formal affair, party \n",
      "\n",
      "Body Types:  straight & narrow, pear, athletic, apple, petite, full bust, hourglass \n",
      "\n",
      "Clothing Categories:  culottes, print, duster, pants, shift, combo, crewneck, jeans, tee, hoodie, gown, sweatpants, cami, skirt, t-shirt, peacoat, cardigan, shirtdress, trouser, skirts, tunic, tight, trousers, maxi, culotte, overalls, poncho, pullover, overcoat, knit, leggings, top, dress, blouson, suit, jacket, down, coat, tank, pant, blazer, trench, vest, henley, turtleneck, jogger, parka, buttondown, sweatshirt, kaftan, for, skort, romper, shirt, ballgown, sweatershirt, sweater, legging, jumpsuit, caftan, cape, bomber, mini, sheath, frock, midi, kimono, blouse \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit Options: \", ', '.join(fit_options), \"\\n\")\n",
    "print(\"Rental Reasons: \", ', '.join(rental_reasons), \"\\n\")\n",
    "print(\"Body Types: \", ', '.join(body_types), \"\\n\")\n",
    "print(\"Clothing Categories: \", ', '.join(clothing_categories), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries missing rental reason: 9 / 150000\n",
      "Entries missing body type: 11358 / 150000\n",
      "Entries missing age: 742 / 150000\n"
     ]
    }
   ],
   "source": [
    "# Determine # entries without 'rented for'\n",
    "missing_rent_reason_count = 0\n",
    "missing_body_type_count = 0\n",
    "missing_age_count = 0\n",
    "for d in training_data:\n",
    "    if 'rented for' not in d:\n",
    "        missing_rent_reason_count += 1\n",
    "    if 'body type' not in d:\n",
    "        missing_body_type_count += 1\n",
    "    if 'age' not in d:\n",
    "        missing_age_count += 1\n",
    "\n",
    "print(\"Entries missing rental reason:\", missing_rent_reason_count, \"/\", len(training_data))\n",
    "print(\"Entries missing body type:\", missing_body_type_count, \"/\", len(training_data))\n",
    "print(\"Entries missing age:\", missing_age_count, \"/\", len(training_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Age vs Rating\n",
    "age_vs_rating = np.zeros((len(training_data) - missing_age_count, 2))\n",
    "\n",
    "i = 0\n",
    "for d in training_data:\n",
    "    if 'age' in d:\n",
    "        age_vs_rating[i][0] = d['age']\n",
    "        age_vs_rating[i][1] = d['rating']\n",
    "        i+=1\n",
    "        \n",
    "plt.scatter(age_vs_rating[:,0], age_vs_rating[:,1])\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of Age vs Rating\n",
    "Age versus Rating graph shows age alone is not a strong indicator of rating. Note that individuals of extreme ages (<20 and >80) tend to give higher ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Predictive Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our predictive task is predicting a user's rating on a review of their clothing fit on some given features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One naive baseline predictive model we can use is simply determining if the customer considered the clothing item as \"fit\", which means the item was neither \"small\" nor \"large\". This is a good sign the the customer was satisfied, so we simply guess the rating to be \"10\". Otherwise we guess a random lesser rating from all other possible ratings in the training data. To get these other ratings, we iterated through the training data, and put them in a set.\n",
    "\n",
    "Another naive baseline we can do is selectively find the most common words that are not stop-words used in each rating category. For example, in a \"10\" words that appear may be \"perfect\" or \"great\". We can manually select qualitative words for each category, and our predictor would simply predict that rating if those words appear in a review. We found these words by finding the top 30 most frequent non-stop-words for each rating category in the training data. For reviews that have overlapping words in multiple rating categories, the higher rating category would take precedence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 1: Predict a rating of 10 if the fit = 'fit', otherwise randomly predict a rating in the range of all other rating in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set of other ratings: {'4', '2', '6', '8'}\n",
      "Accuracy = 0.5571569874240497\n"
     ]
    }
   ],
   "source": [
    "# Find ratings that aren't 10\n",
    "other_ratings = set()\n",
    "for d in data:\n",
    "    if d['rating'] != '10':\n",
    "        other_ratings.add(d['rating'])\n",
    "print(\"Set of other ratings:\", other_ratings)\n",
    "\n",
    "def baseline1(data, y):\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        if d['fit'] == 'fit':\n",
    "            predictions.append('10')\n",
    "        else:\n",
    "            predictions.append(random.choice(list(other_ratings)))\n",
    "    return predictions\n",
    "\n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = baseline1(test_data, y_test)\n",
    "correct = [y_test[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline 2: Predict based on specific words that appear in the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words per category\n",
      "2 : ['dress', 'wear', 'fit', 'size', 'would', 'like', 'didnt', 'even', 'small', 'way', 'look', 'short', 'really', 'big', 'im', 'looked', 'wearing', 'tight', 'long', 'made', 'back', 'large', 'could', 'top', 'material', 'fabric', 'also', 'chest', 'couldnt', 'ordered'] \n",
      "\n",
      "4 : ['dress', 'fit', 'wear', 'size', 'would', 'didnt', 'like', 'really', 'small', 'look', 'top', 'wearing', 'short', 'also', 'tight', 'way', 'fabric', 'im', 'back', 'long', 'even', 'big', 'looked', 'waist', 'large', 'made', 'material', 'could', 'pretty', 'great'] \n",
      "\n",
      "6 : ['dress', 'fit', 'would', 'size', 'wear', 'didnt', 'little', 'like', 'really', 'top', 'great', 'bit', 'look', 'small', 'short', 'tight', 'also', 'im', 'fabric', 'long', 'wearing', 'waist', 'color', 'pretty', 'back', 'wore', 'beautiful', 'work', 'made', 'big'] \n",
      "\n",
      "8 : ['dress', 'fit', 'size', 'would', 'little', 'wear', 'great', 'wore', 'bit', 'comfortable', 'loved', 'compliments', 'perfect', 'really', 'like', 'im', 'didnt', 'long', 'top', 'tight', 'got', 'back', 'definitely', 'color', 'bra', '4', 'length', 'night', 'short', 'fabric'] \n",
      "\n",
      "10 : ['dress', 'fit', 'size', 'would', 'wore', 'perfect', 'wear', 'great', 'comfortable', 'little', 'compliments', 'loved', 'like', 'got', 'bra', 'definitely', 'night', 'length', 'im', 'long', 'bit', 'rent', 'didnt', 'back', 'heels', 'really', 'color', 'flattering', 'wedding', '4'] \n",
      "\n",
      "Most common rating: 10\n"
     ]
    }
   ],
   "source": [
    "# Baseline 2 preparation: Find most common words that aren't stop words\n",
    "punct = string.punctuation\n",
    "\n",
    "r2_word_count = defaultdict(int)\n",
    "r4_word_count = defaultdict(int)\n",
    "r6_word_count = defaultdict(int)\n",
    "r8_word_count = defaultdict(int)\n",
    "r10_word_count = defaultdict(int)\n",
    "\n",
    "rating_count = defaultdict(int)\n",
    "for d in data:\n",
    "    t = d['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # Non-punct characters\n",
    "    t = ''.join(t) # Convert back to string\n",
    "    words = t.strip().split() # Tokenizes\n",
    "    \n",
    "    rating_count[d['rating']] += 1\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            if d['rating'] == '2':\n",
    "                r2_word_count[w] += 1\n",
    "            elif d['rating'] == '4':\n",
    "                r4_word_count[w] += 1\n",
    "            elif d['rating'] == '6':\n",
    "                r6_word_count[w] += 1\n",
    "            elif d['rating'] == '8':\n",
    "                r8_word_count[w] += 1\n",
    "            elif d['rating'] == '10':\n",
    "                r10_word_count[w] += 1\n",
    "\n",
    "def top_words(word_count):\n",
    "    counts = [(word_count[w], w) for w in word_count]\n",
    "    counts.sort()\n",
    "    counts.reverse()\n",
    "    return [w[1] for w in counts[:30]]\n",
    "\n",
    "print(\"Most frequent words per category\")\n",
    "word_counts = [(2, r2_word_count), (4, r4_word_count), (6, r6_word_count), (8, r8_word_count), (10, r10_word_count)]\n",
    "for rating, count in word_counts:\n",
    "    print(rating, \":\", top_words(count), \"\\n\")\n",
    "\n",
    "rating_count = [(rating_count[w], w) for w in rating_count]\n",
    "rating_count.sort()\n",
    "rating_count.reverse()\n",
    "print(\"Most common rating: \" + rating_count[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.49053271160096085\n"
     ]
    }
   ],
   "source": [
    "def baseline2(data, y):\n",
    "    predictions = []\n",
    "    for d in data:\n",
    "        # If no review, just choose most common in training set\n",
    "        if not d['review_text']: # if \"review_text\" not in d\n",
    "            predictions.append('10')\n",
    "            continue\n",
    "        t = d['review_text']\n",
    "        t = t.lower() # lowercase string\n",
    "        t = [c for c in t if not (c in punct)] # Non-punct characters\n",
    "        t = ''.join(t) # Convert back to string\n",
    "        words = t.strip().split() # Tokenizes\n",
    "        if \"perfect\" in words:\n",
    "            predictions.append(str(rating_count[0][1]))\n",
    "        elif \"great\" in words:\n",
    "            predictions.append('8')\n",
    "        elif \"little\" in words:\n",
    "            predictions.append('6')\n",
    "        elif \"didnt\" in words:\n",
    "            predictions.append('4')\n",
    "        elif \"couldnt\" in words:\n",
    "            predictions.append('2')\n",
    "        else:\n",
    "            predictions.append(str(rating_count[0][1])) # Most common\n",
    "    return predictions\n",
    "            \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = baseline2(test_data, y_test)\n",
    "correct = [y_test[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our focal predictors, we decided to train logistic regressors with other features // TODO:\n",
    "\n",
    "We can validify our predictions by // TODO: Our baselines were in the 50-60% accuracy range, which is decent considering there are 5 possible predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary 1: Try logistic regressor that just takes into account the length of a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6453063915971928\n"
     ]
    }
   ],
   "source": [
    "def length_feature(datum):\n",
    "    return [1, len(datum['review_text'])]\n",
    "\n",
    "X = [length_feature(d) for d in training_data]    \n",
    "y = [d['rating'] for d in training_data]\n",
    "model = linear_model.LogisticRegression(max_iter=10000)\n",
    "model.fit(X, y)\n",
    "\n",
    "X_test = [length_feature(d) for d in test_data] \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = model.predict(X_test)\n",
    "correct = [y_test[i] == predictions[i] for i in range(len(y_test))]\n",
    "print(\"Accuracy =\", sum(correct) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary 2: Try logistic regressor with features weight, review_text, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formal affair': 0, 'work': 1, 'other': 2, 'vacation': 3, 'party: cocktail': 4, 'party': 5, 'date': 6, 'wedding': 7, 'everyday': 8}\n",
      "\n",
      "{'fit': 0, 'small': 1, 'large': 2}\n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "total_words = 0\n",
    "\n",
    "rented_for_set = set()\n",
    "fit_set = set()\n",
    "\n",
    "for d in training_data:\n",
    "    if 'rented for' in d:\n",
    "        rented_for_set.add(d['rented for'])\n",
    "    if 'fit' in d:\n",
    "        fit_set.add(d['fit'])\n",
    "    t = d['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            total_words += 1\n",
    "            word_count[w] += 1\n",
    "\n",
    "rented_for_ID = dict(zip(list(rented_for_set), range(len(rented_for_set))))\n",
    "fit_ID = dict(zip(list(fit_set), range(len(fit_set))))\n",
    "\n",
    "print(rented_for_ID)\n",
    "print()\n",
    "print(fit_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42863\n",
      "1750\n"
     ]
    }
   ],
   "source": [
    "counts = [(word_count[w], w) for w in word_count]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "counts[:10]\n",
    "print(len(counts))\n",
    "\n",
    "words = [w[1] for w in counts[:1400]]\n",
    "word_ID = dict(zip(words, range(len(words))))\n",
    "word_set = set(words)\n",
    "print(len(word_set))\n",
    "\n",
    "def dictionary_feature(datum):\n",
    "    feat = [0]*len(word_set)\n",
    "    t = datum['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if not (w in word_set): continue\n",
    "        feat[word_ID[w]] += 1\n",
    "    # Get One-hot-encoding for 'rented for' and 'fit'\n",
    "    rented_for_OHE = [0] * len(rented_for_ID)\n",
    "    fit_OHE = [0] * len(fit_ID)\n",
    "    if 'rented for' in datum and datum['rented for'] in rented_for_ID:\n",
    "        rented_for_OHE[rented_for_ID[datum['rented for']]] = 1\n",
    "    if 'fit' in datum and datum['fit'] in fit_ID:\n",
    "        fit_OHE[fit_ID[datum['fit']]] = 1\n",
    "    feat += rented_for_OHE + fit_OHE\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6980829918515379\n"
     ]
    }
   ],
   "source": [
    "X_train = [dictionary_feature(d) for d in training_data]\n",
    "y_train = [d['rating'] for d in training_data]\n",
    "\n",
    "model = linear_model.LogisticRegression(C=1, solver='lbfgs', multi_class='auto', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = [dictionary_feature(d) for d in test_data] \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = model.predict(X_test)\n",
    "print(sum(predictions == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary 3: Try logistic regressor with features weight, review_text, fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'formal affair': 0, 'work': 1, 'other': 2, 'vacation': 3, 'party: cocktail': 4, 'party': 5, 'date': 6, 'wedding': 7, 'everyday': 8}\n",
      "\n",
      "{'fit': 0, 'small': 1, 'large': 2}\n"
     ]
    }
   ],
   "source": [
    "word_count = defaultdict(int)\n",
    "total_words = 0\n",
    "\n",
    "rented_for_set = set()\n",
    "fit_set = set()\n",
    "\n",
    "for d in training_data:\n",
    "    if 'rented for' in d:\n",
    "        rented_for_set.add(d['rented for'])\n",
    "    if 'fit' in d:\n",
    "        fit_set.add(d['fit'])\n",
    "    t = d['review_summary']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            total_words += 1\n",
    "            word_count[w] += 1\n",
    "\n",
    "rented_for_ID = dict(zip(list(rented_for_set), range(len(rented_for_set))))\n",
    "fit_ID = dict(zip(list(fit_set), range(len(fit_set))))\n",
    "\n",
    "print(rented_for_ID)\n",
    "print()\n",
    "print(fit_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13462\n",
      "1500\n"
     ]
    }
   ],
   "source": [
    "counts = [(word_count[w], w) for w in word_count]\n",
    "counts.sort()\n",
    "counts.reverse()\n",
    "counts[:10]\n",
    "print(len(counts))\n",
    "\n",
    "words = [w[1] for w in counts[:1500]]\n",
    "word_id = dict(zip(words, range(len(words))))\n",
    "word_set = set(words)\n",
    "print(len(word_set))\n",
    "\n",
    "def dictionary_summary_feature(datum):\n",
    "    feat = [0]*len(word_set)\n",
    "    t = datum['review_text']\n",
    "    t = t.lower() # lowercase string\n",
    "    t = [c for c in t if not (c in punct)] # non-punct characters\n",
    "    t = ''.join(t) # convert back to string\n",
    "    words = t.strip().split() # tokenizes\n",
    "    for w in words:\n",
    "        if not (w in word_set): continue\n",
    "        feat[word_id[w]] += 1\n",
    "    # Get One-hot-encoding for 'rented for' and 'fit'\n",
    "    rented_for_OHE = [0] * len(rented_for_ID)\n",
    "    fit_OHE = [0] * len(fit_ID)\n",
    "    if 'rented for' in datum and datum['rented for'] in rented_for_ID:\n",
    "        rented_for_OHE[rented_for_ID[datum['rented for']]] = 1\n",
    "    if 'fit' in datum and datum['fit'] in fit_ID:\n",
    "        fit_OHE[fit_ID[datum['fit']]] = 1\n",
    "    feat += rented_for_OHE + fit_OHE\n",
    "    feat.append(1)\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697376477791908\n"
     ]
    }
   ],
   "source": [
    "X_train = [dictionary_summary_feature(d) for d in training_data]\n",
    "y_train = [d['rating'] for d in training_data]\n",
    "\n",
    "model = linear_model.LogisticRegression(C=1, solver='lbfgs', multi_class='auto', max_iter=10000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "X_test = [dictionary_summary_feature(d) for d in test_data] \n",
    "y_test = [d['rating'] for d in test_data]\n",
    "predictions = model.predict(X_test)\n",
    "print(sum(predictions == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Justification for Proposed Model, Optimizations, Issues, Model Alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Literature Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data was orignally scraped by Rishabh Misra, Mengting Wan, and Julian McAuley, all affiliated with the University of California, San Diego. It was used for a paper titled *Decomposing Fit Semantics for Product Size Recommendation in Metric Spaces* which gave insight in how to tackle the product fit problem for online clothing retailers, to decrease the amount of return rates, which can be expensive. One of the datasets in the paper was our dataset, which were fit reviews obtained from *RentTheRunWay*, which is an online company that rents designer clothing and accessories.\n",
    "\n",
    "Another dataset used in the paper is from *ModCloth*, which was used in the same way. Together these datasets were used with techniques that include \"Learning Fit Semantics\" and \"Metric Learning\".\n",
    "\n",
    "Another paper, *SizeNet: Weakly Supervised Learning of Visual Size and Fit in Fashion Images* by Nour Karessli, Romain Guigoures, and Reza Shirvany, tackled this problem with other approaches with methods \"Teacher-Student Learning\" and \"Statistical Modeling.\"\n",
    "\n",
    "These works are different from our own findings, because our goals are different. While they are trying to model how well a clothing item fits, we are simply guessing how a user would rate how well a clothing item fits from previous purchases/rentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Results and Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citations:\n",
    "\n",
    "#### Decomposing fit semantics for product size recommendation in metric spaces\n",
    "\n",
    "Rishabh Misra, Mengting Wan, Julian McAuley\n",
    "\n",
    "*RecSys, 2018*\n",
    "\n",
    "http://cseweb.ucsd.edu/~jmcauley/pdfs/recsys18e.pdf\n",
    "\n",
    "#### SizeNet: Weakly Supervised Learning of Visual Size and Fit in Fashion Images\n",
    "\n",
    "Nour Karessli, Romain Guigoures, Reza Shirvany\n",
    "\n",
    "*Zalando SE, 2019*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
